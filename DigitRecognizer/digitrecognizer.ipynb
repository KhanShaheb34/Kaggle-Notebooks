{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "X_train = train_df.drop([\"label\"], axis=1)\n",
    "Y_train = train_df[\"label\"]\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, 28, 28, 1)\n",
    "Y_train = np.array(Y_train).reshape(-1, 1)\n",
    "X_test = np.array(test_df).reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42000 training examples\n",
      "There are 28000 testing examples\n",
      "There are 10 classes\n",
      "Image shape: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "n_classes = Y_train.shape[1]\n",
    "image_size = X_train.shape[1:]\n",
    "\n",
    "print(f\"There are {n_train} training examples\")\n",
    "print(f\"There are {n_test} testing examples\")\n",
    "print(f\"There are {n_classes} classes\")\n",
    "print(f\"Image shape: {image_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)\n",
    "train_gen = datagen.flow(X_train, Y_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fce4c043890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 5\n",
    "printing_digit = X_train[index].reshape(28, 28)\n",
    "plt.imshow(printing_digit, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 327,242\n",
      "Trainable params: 326,410\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28,28,1), name='digits'),\n",
    "    Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (5,5), strides=2, padding=\"same\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (5,5), strides=2, padding=\"same\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Conv2D(128, (4,4), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "657/657 [==============================] - 100s 153ms/step - loss: 0.4336 - accuracy: 0.8668\n",
      "Epoch 2/50\n",
      "657/657 [==============================] - 102s 155ms/step - loss: 0.1284 - accuracy: 0.9616\n",
      "Epoch 3/50\n",
      "657/657 [==============================] - 108s 164ms/step - loss: 0.0946 - accuracy: 0.9704\n",
      "Epoch 4/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0829 - accuracy: 0.9757\n",
      "Epoch 5/50\n",
      "657/657 [==============================] - 100s 152ms/step - loss: 0.0722 - accuracy: 0.9782\n",
      "Epoch 6/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0636 - accuracy: 0.9810\n",
      "Epoch 7/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0577 - accuracy: 0.9822\n",
      "Epoch 8/50\n",
      "657/657 [==============================] - 100s 152ms/step - loss: 0.0610 - accuracy: 0.9816\n",
      "Epoch 9/50\n",
      "657/657 [==============================] - 98s 150ms/step - loss: 0.0536 - accuracy: 0.9840\n",
      "Epoch 10/50\n",
      "657/657 [==============================] - 100s 152ms/step - loss: 0.0489 - accuracy: 0.9848\n",
      "Epoch 11/50\n",
      "657/657 [==============================] - 100s 153ms/step - loss: 0.0470 - accuracy: 0.9863\n",
      "Epoch 12/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0446 - accuracy: 0.9861\n",
      "Epoch 13/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0456 - accuracy: 0.9867\n",
      "Epoch 14/50\n",
      "657/657 [==============================] - 100s 152ms/step - loss: 0.0413 - accuracy: 0.9875\n",
      "Epoch 15/50\n",
      "657/657 [==============================] - 98s 150ms/step - loss: 0.0395 - accuracy: 0.9881\n",
      "Epoch 16/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0375 - accuracy: 0.9888\n",
      "Epoch 17/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0352 - accuracy: 0.9892\n",
      "Epoch 18/50\n",
      "657/657 [==============================] - 99s 150ms/step - loss: 0.0386 - accuracy: 0.9891\n",
      "Epoch 19/50\n",
      "657/657 [==============================] - 99s 150ms/step - loss: 0.0332 - accuracy: 0.9904\n",
      "Epoch 20/50\n",
      "657/657 [==============================] - 99s 150ms/step - loss: 0.0253 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "657/657 [==============================] - 100s 152ms/step - loss: 0.0240 - accuracy: 0.9925\n",
      "Epoch 36/50\n",
      "657/657 [==============================] - 99s 150ms/step - loss: 0.0228 - accuracy: 0.9932\n",
      "Epoch 41/50\n",
      "657/657 [==============================] - 99s 151ms/step - loss: 0.0190 - accuracy: 0.9940\n",
      "Epoch 42/50\n",
      "657/657 [==============================] - 99s 150ms/step - loss: 0.0208 - accuracy: 0.9940\n",
      "Epoch 43/50\n",
      "513/657 [======================>.......] - ETA: 21s - loss: 0.0241 - accuracy: 0.9933"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fce4635e250>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAANF0lEQVR4nO3db6xU9Z3H8c9HhEQBDSwKaFn7R2JqNsEaJGtaNzWkDcsT5AFaHjRsQnqrqSskPFjDPiiPTLPpH1cfkFyUFDZdCbG48qDZLSE1tjH+uRJULCm6DbRwr1wbSSpqrOB3H9zD9gpzzlzmzJkZ+L5fyc3MnO+cM99M+HDOzG/O+TkiBODyd0W/GwDQG4QdSIKwA0kQdiAJwg4kcWUvX8w2X/0DDYsIt1pea89ue4Xt39l+2/bDdbYFoFnudJzd9jRJRyR9Q9JxSa9IWhsRv61Yhz070LAm9uzLJL0dEb+PiL9I2iVpVY3tAWhQnbDfKOmPkx4fL5Z9hu0h2yO2R2q8FoCa6nxB1+pQ4YLD9IgYljQscRgP9FOdPftxSYsmPf6cpNF67QBoSp2wvyJpse0v2J4h6VuS9nanLQDd1vFhfEScsf2gpP+RNE3S9oh4s2udAeiqjofeOnoxPrMDjWvkRzUALh2EHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ6np9dkmwflfS+pLOSzkTE0m40BaD7aoW9cHdE/KkL2wHQIA7jgSTqhj0k/dL2q7aHWj3B9pDtEdsjNV8LQA2OiM5Xtm+IiFHb10vaJ+mfI+L5iud3/mIApiQi3Gp5rT17RIwWt+OSnpG0rM72ADSn47Dbnml79rn7kr4p6VC3GgPQXXW+jZ8v6Rnb57bznxHx313pCkDX1frMftEvxmd2oHGNfGYHcOkg7EAShB1IgrADSRB2IIlunAhzSbjqqqsq6wcPHqysL168uLT2zjvvVK575513VtaPHTtWWQe6gT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiSRZpx91qxZlfUZM2ZU1qvODpw/f37lujt37qysv/vuu5X1rVu3Vtbr2L9/f2PbxmBhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXB12cLNN99cWd+8eXNpbd26dd1up2defPHFyvqBAwcq66+99lo32/mMvXv3VtbHx8cbe+1LGVeXBZIj7EAShB1IgrADSRB2IAnCDiRB2IEkGGefopkzZ5bWHnroocp177333sr6ggULKutXX311Zf3s2bOltWuvvbZy3WLK7VK9/Pdxvo8//riy/vjjj1fWt2zZUlr76KOPOmnpktDxOLvt7bbHbR+atGyu7X223ypu53SzWQDdN5XD+J9KWnHesocl7Y+IxZL2F48BDLC2YY+I5yW9d97iVZJ2FPd3SLqny30B6LJOr0E3PyLGJCkixmxfX/ZE20OShjp8HQBd0vgFJyNiWNKwdGl/QQdc6jodejtpe6EkFbecfgQMuE7DvlfSufM610l6tjvtAGhK23F2209J+rqkeZJOSvq+pP+StFvS30r6g6Q1EXH+l3ittsVhfAduueWWyvrp06dLa3fddVfluhs2bKis1x1nnz59emnt9ttvr7Xtdvbs2VNaW7NmTaOv3U9l4+xtP7NHxNqS0vJaHQHoKX4uCyRB2IEkCDuQBGEHkiDsQBKc4opG1Rl6e+KJJyrrt956a2X90KFDpbUlS5ZUrnsp41LSQHKEHUiCsANJEHYgCcIOJEHYgSQIO5BE41eqQW6ffPJJaW1kZKRy3Q8//LDWa7/wwgu11r/csGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4nx2NuvLK8p9yPPLII5Xrbtq0qbL+wQcfVNavueaayvrlivPZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJzmdHo5YuXVpaazeO3k7VlMy4UNs9u+3ttsdtH5q0bIvtE7YPFn8rm20TQF1TOYz/qaQVLZb/JCJuK/5+0d22AHRb27BHxPOS3utBLwAaVOcLugdtv14c5s8pe5LtIdsjtqsvOAagUZ2GfaukL0m6TdKYpB+VPTEihiNiaUSUf1MDoHEdhT0iTkbE2Yj4VNI2Scu62xaAbuso7LYXTnq4WlL53LgABkLb89ltPyXp65LmSTop6fvF49skhaSjkr4bEWNtX4zz2dM5ceJEaW3BggWV6x45cqSyvnz58sr66OhoZf1yVXY+e9sf1UTE2haLn6zdEYCe4ueyQBKEHUiCsANJEHYgCcIOJMEprqhlxYpW50j91XXXXVdau+KK6n3No48+WlnPOrTWKfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+yotGTJksr6rl27KuvTpk0rre3bt69y3d27d1fWcXHYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzo9K8efMq67Nnz+5429u3b6+snzp1quNt40Ls2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZk6s631ySNm7cWGv7x44dK609/fTTtbaNi9N2z257ke1f2T5s+03bG4rlc23vs/1WcTun+XYBdGoqh/FnJG2KiC9L+ntJ37N9q6SHJe2PiMWS9hePAQyotmGPiLGIOFDcf1/SYUk3SlolaUfxtB2S7mmqSQD1XdRndtufl/QVSS9Jmh8RY9LEfwi2ry9ZZ0jSUL02AdQ15bDbniXp55I2RsSfbU9pvYgYljRcbCM6aRJAfVMaerM9XRNB/1lE7CkWn7S9sKgvlDTeTIsAuqHtnt0Tu/AnJR2OiB9PKu2VtE7SD4rbZxvpEI266aabKusrV66stf1t27aV1s6cOVNr27g4UzmM/6qkb0t6w/bBYtlmTYR8t+31kv4gaU0zLQLohrZhj4jfSCr7gL68u+0AaAo/lwWSIOxAEoQdSIKwA0kQdiAJTnFN7vTp05X10dHRyvoNN9zQzXbQIPbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zJjY9XX3PkpZdeqqyvXr26sn7HHXdcdE9oBnt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUjCEb2bpIUZYS497c5XbzcOP3fu3NLa3XffXbnuyy+/XFlHaxHR8mrQ7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm24+y2F0naKWmBpE8lDUfEv9veIuk7kt4tnro5In7RZluMs19mHnvsscr6/fffX1p77rnnKte97777KuunTp2qrGdVNs4+lYtXnJG0KSIO2J4t6VXb+4raTyLih91qEkBzpjI/+5ikseL++7YPS7qx6cYAdNdFfWa3/XlJX5F07jeSD9p+3fZ223NK1hmyPWJ7pFanAGqZcthtz5L0c0kbI+LPkrZK+pKk2zSx5/9Rq/UiYjgilkbE0i70C6BDUwq77emaCPrPImKPJEXEyYg4GxGfStomaVlzbQKoq23YbVvSk5IOR8SPJy1fOOlpqyUd6n57ALplKkNvX5P0a0lvaGLoTZI2S1qriUP4kHRU0neLL/OqtsXQWzLr168vrQ0PD1eu267+wAMPdNTT5a7jobeI+I2kVitXjqkDGCz8gg5IgrADSRB2IAnCDiRB2IEkCDuQBJeSBi4zXEoaSI6wA0kQdiAJwg4kQdiBJAg7kARhB5KYytVlu+lPko5NejyvWDaIBrW3Qe1LordOdbO3m8oKPf1RzQUvbo8M6rXpBrW3Qe1LordO9ao3DuOBJAg7kES/w159kbH+GtTeBrUvid461ZPe+vqZHUDv9HvPDqBHCDuQRF/CbnuF7d/Zftv2w/3ooYzto7bfsH2w3/PTFXPojds+NGnZXNv7bL9V3LacY69PvW2xfaJ47w7aXtmn3hbZ/pXtw7bftL2hWN7X966ir568bz3/zG57mqQjkr4h6bikVyStjYjf9rSREraPSloaEX3/AYbtf5B0WtLOiPi7Ytm/SXovIn5Q/Ec5JyL+ZUB62yLpdL+n8S5mK1o4eZpxSfdI+if18b2r6Ote9eB968eefZmktyPi9xHxF0m7JK3qQx8DLyKel/TeeYtXSdpR3N+hiX8sPVfS20CIiLGIOFDcf1/SuWnG+/reVfTVE/0I+42S/jjp8XEN1nzvIemXtl+1PdTvZlqYf26areL2+j73c76203j30nnTjA/Me9fJ9Od19SPsra6PNUjjf1+NiNsl/aOk7xWHq5iaKU3j3SstphkfCJ1Of15XP8J+XNKiSY8/J2m0D320FBGjxe24pGc0eFNRnzw3g25xO97nfv7fIE3j3WqacQ3Ae9fP6c/7EfZXJC22/QXbMyR9S9LePvRxAdsziy9OZHumpG9q8Kai3itpXXF/naRn+9jLZwzKNN5l04yrz+9d36c/j4ie/0laqYlv5P9X0r/2o4eSvr4o6bXi781+9ybpKU0c1n2iiSOi9ZL+RtJ+SW8Vt3MHqLf/0MTU3q9rIlgL+9Tb1zTx0fB1SQeLv5X9fu8q+urJ+8bPZYEk+AUdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTxfwBjIa7L7StIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 98\n",
    "printing_digit = X_test[index].reshape(28, 28)\n",
    "print(Y_pred[index])\n",
    "plt.imshow(printing_digit, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ImageId\": range(1, 28001),\n",
    "    \"Label\": Y_pred.tolist()\n",
    "})\n",
    "submission.to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
